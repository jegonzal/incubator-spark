package spark.rdd

import spark.Dependency
import spark.NarrowDependency
import spark.Partition
import spark.RDD
import spark.TaskContext


class SplitRDD[T: ClassManifest](
    @transient var prev: RDD[T],
    partitionIndices: Array[Int])
  extends RDD[T](prev.context, Nil) {  // Nil since we implement getDependencies

  override def getPartitions: Array[Partition] = {
    partitionIndices.zipWithIndex.map { case (part, i) =>
      new CoalescedRDDPartition(i, prev, Array(part))
    }
  }

  override def compute(split: Partition, context: TaskContext): Iterator[T] = {
    split.asInstanceOf[CoalescedRDDPartition].parents.iterator.flatMap { parentSplit =>
      firstParent[T].iterator(parentSplit, context)
    }
  }

  override def getDependencies: Seq[Dependency[_]] = {
    Seq(new NarrowDependency(prev) {
      def getParents(id: Int): Seq[Int] = {
        partitions(id).asInstanceOf[CoalescedRDDPartition].parentsIndices
      }
    })
  }

  override def clearDependencies() {
    super.clearDependencies()
    prev = null
  }
}

